{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from functools import cached_property\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "old_dir = Path().absolute()\n",
    "os.chdir('..')\n",
    "from keys import API_KEY\n",
    "os.environ['OPENAI_API_KEY'] = API_KEY\n",
    "os.chdir(old_dir)\n",
    "\n",
    "\n",
    "import fitz\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "models = ['gpt-4', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_latex_document_str(header, data_description, main_text):\n",
    "    main_text = main_text.replace(\"\\n\\n\", \" \\\\\\\\\\n\\\\\\\\\\n\").replace('%', r'\\%')\n",
    "    data_description = data_description.replace(\"\\n\\n\", \" \\\\\\\\\\n\\\\\\\\\\n\").replace('%', r'\\%')\n",
    "    string = (\n",
    "        r\"\\documentclass{article}\"+\"\\n\"\n",
    "        r\"\\title{\"+header+\"}\"+\"\\n\"\n",
    "        r\"\\author{ChatGPT}\"+\"\\n\"\n",
    "        r\"\\begin{document} \"+\"\\n\\n\"\n",
    "        r\"\\maketitle\"+\"\\n\"\n",
    "        r\"\\section{Data}\"+\"\\n\"\n",
    "        r\"\"+data_description+\" \\n\"\n",
    "        r\"\\section{Summary}\"+\"\\n\"\n",
    "        r\"\"+main_text+\" \\n\\n\"\n",
    "        r\"\\end{document}\"\n",
    "    )\n",
    "    return string    \n",
    "\n",
    "@dataclass\n",
    "class PdfLLM:\n",
    "    filepath: str\n",
    "    model_name: str = 'gpt-3.5-turbo-16k'\n",
    "    temperature: float = 0\n",
    "    #'gpt-4'\n",
    "\n",
    "    def __post_init__(self):\n",
    "\n",
    "        self.llm = ChatOpenAI(temperature=0, model_name=self.model_name)\n",
    "\n",
    "        self.detailed_prompt_template = (\n",
    "            \"Write a detailed summary of the text.\" \n",
    "            \"The summary should be up to 2000 words.\" \n",
    "            \"Do not summarise any graphs, charts or exhibits.\"\n",
    "            \"Do not summarise the list of references.\"\n",
    "            \"Do not summarise the appendix.\"\n",
    "            \"Make sure that it is clear what you are summarising in each step.\"\n",
    "            \"Be concise, but don't miss details.\"\n",
    "            \"The text is:\\n\"\n",
    "            \"{text}\\n\\n\"\n",
    "            \"DETAILED SUMMARY:\")\n",
    "\n",
    "        self.concise_prompt_template = (\n",
    "            \"Write a concise summary of the following:\\n\"\n",
    "            \"{text}\\n\\n\"\n",
    "            \"CONCISE SUMMARY:\")\n",
    "        \n",
    "        self.refine_template = (\n",
    "            \"Your job is to produce a final summary\\n\"\n",
    "            \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "            \"We have the opportunity to refine the existing summary\"\n",
    "            \"(only if needed) with some more context below.\\n\"\n",
    "            \"------------\\n\"\n",
    "            \"{text}\\n\"\n",
    "            \"------------\\n\"\n",
    "            \"Given the new context, refine the original summary.\"\n",
    "            \"If the context isn't useful, return the original summary.\"\n",
    "        )\n",
    "\n",
    "        self.data_question = 'What data is used in the study, what countries are they using and what is the timeframe? '\n",
    "        self.logger = logging.getLogger(f'{self.filepath}.log')\n",
    "\n",
    "    def save_latex_summary(self, title, filename:str = None):\n",
    "        filename = title if not filename else filename \n",
    "        filename = filename if '.tex' in filename else filename+'.tex'\n",
    "        summary_text = self.detailed_summary\n",
    "        data_description = self.ask_question(self.data_question)\n",
    "        latex_str = make_latex_document_str(title, data_description, summary_text)\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(latex_str)\n",
    "\n",
    "        self.logger.info(f'FILE: {filename} CREATED')\n",
    "        \n",
    "    def ask_question(self, question):\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size = 1000,\n",
    "            chunk_overlap = 50\n",
    "        )\n",
    "        splits = text_splitter.split_documents(self.pages)\n",
    "        vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "        qa_chain = RetrievalQA.from_chain_type(self.llm,retriever=vectorstore.as_retriever())\n",
    "        return qa_chain({\"query\": question})['result']\n",
    "\n",
    "    @cached_property\n",
    "    def concise_summary(self):\n",
    "        return self.get_summary(self.concise_prompt_template)\n",
    "    \n",
    "    @cached_property\n",
    "    def detailed_summary(self):\n",
    "        return self.get_summary(self.detailed_prompt_template)\n",
    "\n",
    "    def get_summary(self, promt_template):\n",
    "        chain = self.get_chain(promt_template)\n",
    "        pages = self.pages\n",
    "        self.logger.info('RUNNING CHAIN..')\n",
    "        result = chain({\"input_documents\": pages}, return_only_outputs=True)\n",
    "        self.logger.info('SUMMARY FINISHED')\n",
    "        return result['output_text']\n",
    "    \n",
    "    @cached_property\n",
    "    def pages(self):\n",
    "        loader = PyPDFLoader(self.filepath)\n",
    "        pages = loader.load()\n",
    "        self.logger.info('LOADED PAGES')\n",
    "        return pages \n",
    "\n",
    "    def get_chain(self, prompt_template):\n",
    "        prompt = PromptTemplate.from_template(prompt_template)\n",
    "        refine_prompt = PromptTemplate.from_template(self.refine_template)\n",
    "        chain = load_summarize_chain(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"refine\",\n",
    "            question_prompt=prompt,\n",
    "            refine_prompt=refine_prompt,\n",
    "            return_intermediate_steps=False,\n",
    "            input_key=\"input_documents\",\n",
    "            output_key=\"output_text\",\n",
    "        )\n",
    "        self.logger.info('CREATED CHAIN')\n",
    "        return chain\n",
    "\n",
    "\n",
    "\n",
    "class PdfLLMStuff(PdfLLM):\n",
    "\n",
    "    # def __post_init__(self):\n",
    "    #     super().__post_init__()\n",
    "\n",
    "    def get_chain(self, prompt_template):\n",
    "\n",
    "        prompt = PromptTemplate.from_template(prompt_template)        \n",
    "        llm_chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "        # Define StuffDocumentsChain\n",
    "        stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
    "        self.logger.info('CREATED CHAIN')\n",
    "        return stuff_chain\n",
    "    \n",
    "    def get_summary(self, promt_template):\n",
    "        chain = self.get_chain(promt_template)\n",
    "        pages = self.pages\n",
    "        self.logger.info('RUNNING CHAIN..')\n",
    "        result = chain.run(pages)\n",
    "        self.logger.info('SUMMARY FINISHED')\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [Path().cwd().joinpath('papers').joinpath(paper) for paper in os.listdir('papers')]\n",
    "path = paths[7]\n",
    "\n",
    "pdfllm = PdfLLM(str(path), model_name='gpt-3.5-turbo')\n",
    "pdfllmstuff = PdfLLMStuff(str(path), model_name='gpt-4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/Users/niklasgaertner/Desktop/coding/gpt_research/papers/factor_momentum_everywhere.pdf.log:CREATED CHAIN\n",
      "INFO:/Users/niklasgaertner/Desktop/coding/gpt_research/papers/factor_momentum_everywhere.pdf.log:LOADED PAGES\n",
      "INFO:/Users/niklasgaertner/Desktop/coding/gpt_research/papers/factor_momentum_everywhere.pdf.log:RUNNING CHAIN..\n",
      "INFO:/Users/niklasgaertner/Desktop/coding/gpt_research/papers/factor_momentum_everywhere.pdf.log:SUMMARY FINISHED\n",
      "INFO:chromadb.telemetry.posthog:Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:/Users/niklasgaertner/Desktop/coding/gpt_research/papers/factor_momentum_everywhere.pdf.log:FILE: summaries/gpt_3_2_factor_momentum_everywhere_summary.tex CREATED\n"
     ]
    }
   ],
   "source": [
    "pdfllm.save_latex_summary('Factor Momentum Everywhere', str(Path('summaries').joinpath('gpt_3_2_'+path.name.split('.')[0]+'_summary')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(path):\n",
    "\n",
    "    \"\"\"returns the title of the document based on text size, position and page\"\"\"\n",
    "\n",
    "    NON_TITLE_WORDS = ['draft', 'journal']\n",
    "\n",
    "    pdf_details_list = []\n",
    "    with fitz.open(path) as doc:\n",
    "        for page_no, page in enumerate(doc.pages()):\n",
    "            blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "            for block in blocks: \n",
    "                block_no = block['number']\n",
    "                block_str = ''\n",
    "                block_bold = []\n",
    "                block_italic = []\n",
    "                if 'lines' in block.keys():\n",
    "                    for line in block['lines']:\n",
    "                        for span in line['spans']:\n",
    "                            block_str += span['text']\n",
    "                            location_x = span['origin'][0]\n",
    "                            location_y = span['origin'][1]\n",
    "                            size = span['size']\n",
    "\n",
    "                # add block to pdf_details if block has text\n",
    "                if len(block_str.strip()) > 0:\n",
    "                    pdf_details_list.append([page_no, block_no ,block_str, location_x, location_y, size])\n",
    "\n",
    "    pdf_details = pd.DataFrame(pdf_details_list, columns=['page', 'block', 'text', 'location_x', 'location_y', 'size']).set_index(['page', 'block'])\n",
    "    pdf_details['text'] = pdf_details['text'].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii')) #remove weird encoding\n",
    "\n",
    "    pdf_details = pdf_details.loc[pdf_details.text.str.strip() != '']\n",
    "    for no_word in NON_TITLE_WORDS:\n",
    "        pdf_details = pdf_details.loc[~pdf_details.text.str.lower().str.contains(no_word)]\n",
    "    three_largest = pdf_details.loc[pdf_details['size'].isin(sorted(pdf_details['size'].unique())[-4:])]    \n",
    "    title = three_largest.loc[0].sort_values('location_y')['text'].iat[0]\n",
    "    if len(title) < 3:\n",
    "        title = three_largest.iloc[0]['text']\n",
    "\n",
    "    return title\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_details = details_dict['/Users/niklasgaertner/Desktop/coding/gpt_research/notebooks/papers/a_five_factor_asset_pricing_model.pdf']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>location_x</th>\n",
       "      <th>location_y</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th>block</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>34</th>\n",
       "      <td>Journal of Financial Economics</td>\n",
       "      <td>194.264496</td>\n",
       "      <td>133.619019</td>\n",
       "      <td>14.223766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A five-factor asset pricing model$</td>\n",
       "      <td>273.407806</td>\n",
       "      <td>205.505615</td>\n",
       "      <td>9.698017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a r t i c l e i n f o</td>\n",
       "      <td>62.850399</td>\n",
       "      <td>289.524475</td>\n",
       "      <td>9.143793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a b s t r a c t</td>\n",
       "      <td>223.007797</td>\n",
       "      <td>289.524475</td>\n",
       "      <td>9.143793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text  location_x  location_y  \\\n",
       "page block                                                               \n",
       "0    34         Journal of Financial Economics  194.264496  133.619019   \n",
       "     2      A five-factor asset pricing model$  273.407806  205.505615   \n",
       "     5                   a r t i c l e i n f o   62.850399  289.524475   \n",
       "     9                         a b s t r a c t  223.007797  289.524475   \n",
       "\n",
       "                 size  \n",
       "page block             \n",
       "0    34     14.223766  \n",
       "     2       9.698017  \n",
       "     5       9.143793  \n",
       "     9       9.143793  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_largest = pdf_details.loc[pdf_details['size'].isin(sorted(pdf_details['size'].unique())[-3:])]\n",
    "three_largest.sort_values('location_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page  block\n",
       "0     2        False\n",
       "      5        False\n",
       "      9        False\n",
       "      34        True\n",
       "Name: text, dtype: bool"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PdfLLMRefine Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_llm import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# get paths to papers\n",
    "paths = [Path().cwd().joinpath('factor_momentum_papers').joinpath(paper) for paper in os.listdir('factor_momentum_papers')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an instance of PdfLLMRefine\n",
    "the argumemts we can use are: \n",
    "* **filepath**: path to the pdf that we want to summarise\n",
    "* **model_name**: name of the OpenAI model (e.g. gpt-4 or gpt3.5-turbo)\n",
    "* **temperature**: higher values make the output more random\n",
    "\n",
    "\\\n",
    "The other class we can use is PdfLLMStuff. This class uses the Stuff \\\n",
    "method to generate summaries. These are not as reliable as those \\\n",
    "generated with refine, but much faster to generate. Also the Stuff \\\n",
    "does not work with gpt models that don't allow a lot of tokens.\n",
    "\n",
    "\n",
    "\\\n",
    "Note: gpt-4 only works of you have paid openai before \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_llm_refine = PdfLLMRefine(\n",
    "    filepath = paths[0],\n",
    "    model_name= 'gpt-3.5-turbo',\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can ask the Pdf questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_llm_refine.ask_question('What data are the authors using?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or we can generate a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_llm_refine.detailed_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can add this save this summary as a .tex file. \n",
    "(In VSCode we can install the Latex Workshop extension to generate PDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_llm_refine.save_latex_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of Summaries can be found in fmom_summaries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
